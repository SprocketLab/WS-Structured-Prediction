{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "from typing import Any, DefaultDict, Dict, List, NamedTuple, Optional, Set, Tuple, Union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Decomposition Label Model\n",
    "\n",
    "The implementation contains a few utility functions leading up to the main tensor decomposition method (tensor_decomp). Afterwards, we give the label model, which includes a new fit() method that calls a helper function mu_recovery.\n",
    "\n",
    "References are all to Anima's paper https://arxiv.org/pdf/1210.7559.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimap(A, V_array):\n",
    "    \"\"\"Compute a tensor product as a multilinear map.(pg. 2778, Section 2)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        A\n",
    "            A multidimensional tensor\n",
    "        V_array\n",
    "            Array of vectors to compute tensor against\n",
    "\n",
    "    \"\"\"\n",
    "    p = len(V_array)\n",
    "    for i in range(len(V_array)):\n",
    "        if len(V_array[i].shape) == 1:\n",
    "            V_array[i] = np.expand_dims(V_array[i], axis=1)\n",
    "\n",
    "    n = V_array[0].shape[0]\n",
    "    dims = [a.shape[1] for a in V_array]\n",
    "    dim_ranges = [range(a.shape[1]) for a in V_array]\n",
    "    B = np.zeros(dims)\n",
    "\n",
    "    all_indices = list(itertools.product(*dim_ranges)) #i_1,...,i_p\n",
    "    all_vectors = list(itertools.product(range(n), repeat=p)) #j_1,...,j_p\n",
    "\n",
    "    for ind in all_indices:\n",
    "        for vec in all_vectors:\n",
    "            tmp = A[vec]\n",
    "            for k in range(p):\n",
    "                tmp *= V_array[k][vec[k], ind[k]]\n",
    "            B[ind] += tmp\n",
    "    return B\n",
    "\n",
    "def two_tensor_prod(w, x, y):\n",
    "    \"\"\"\n",
    "    A type of outer product\n",
    "    \"\"\"\n",
    "    r = x.shape[0]\n",
    "    M2 = np.zeros([r, r])\n",
    "\n",
    "    for a in range(w.shape[0]):\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(y.shape[0]):\n",
    "                M2[i,j] += w[a] * x[i,a] * y[j,a]\n",
    "\n",
    "    return M2\n",
    "\n",
    "def three_tensor_prod(w, x, y, z):\n",
    "    \"\"\"\n",
    "    Three-way outer product\n",
    "    \"\"\"\n",
    "    r = x.shape[0]\n",
    "    M3 = np.zeros([r, r, r])\n",
    "\n",
    "    if len(w.shape) == 0:\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(y.shape[0]):\n",
    "                for k in range(z.shape[0]):\n",
    "                    M3[i,j,k] += w * x[i] * y[j] * z[k]\n",
    "    else:\n",
    "        for a in range(w.shape[0]):\n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(y.shape[0]):\n",
    "                    for k in range(z.shape[0]):\n",
    "                        M3[i,j,k] += w[a] * x[i,a] * y[j,a] * z[k,a]\n",
    "\n",
    "    return M3\n",
    "\n",
    "def T_map(T, u):\n",
    "    \"\"\" Power method base transformation (pg. 2790, equation (5))\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        T\n",
    "            A multidimensional tensor\n",
    "        u\n",
    "            A candidate eigenvector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t   \n",
    "            Transformed candidate\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d = u.shape[0]\n",
    "    t = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                t[i] += T[i,j,k] * u[j] * u[k]\n",
    "    return t\n",
    "\n",
    "def tensor_decomp(M2, M3, comps):\n",
    "    \"\"\"Tensor Decomposition Algorithm (pg. 2795, Algorithm 1)\n",
    "    This is combined with reduction (4.3.1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M2\n",
    "        Symmetric matrix to aid the decomposition\n",
    "    M3\n",
    "        Symmetric tensor to be decomposed\n",
    "    comps\n",
    "        Number of eigencomponents to return\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mu_rec\n",
    "        Recovered eigenvectors (a matrix with #comps eigenvectors)\n",
    "    lam_rec\n",
    "        Recovered eigenvalues (a vector with #comps eigenvalues)\n",
    "\n",
    "    \"\"\"\n",
    "    lam_rec = np.zeros(comps)\n",
    "    mu_rec = np.zeros((M2.shape[0], comps))\n",
    "\n",
    "    for b in range(comps):\n",
    "        # initial eigendecomposition used in reduction (4.3.1)\n",
    "        lam, v = np.linalg.eigh(M2)\n",
    "        idx = lam.argsort()[::-1]\n",
    "        lam = lam[idx]\n",
    "        v = v[:, idx]\n",
    "\n",
    "        # keep only the positive eigenvalues\n",
    "        n_eigpos = np.sum(lam > 1e-1)\n",
    "        if n_eigpos > 0:\n",
    "            W = v[:, :n_eigpos] @ np.diag(1.0 / np.sqrt(np.abs(lam[:n_eigpos])))\n",
    "\n",
    "            B = np.linalg.pinv(W.T)  # TODO look into this\n",
    "            M3_tilde = multimap(M3, [W, W, W])  # reduction complete\n",
    "\n",
    "            # decomposition setup\n",
    "            # TODO try different hps if this doesn't work\n",
    "            N = 10  # number of power iterations\n",
    "            restarts = 1000  # number of random restarts # NOTE critical\n",
    "            tau_star = 0  # best robust eigenvalue so far\n",
    "            u_star = np.zeros(n_eigpos)  # best eigenvector so far\n",
    "\n",
    "            # repeated restarts to find best eigenvector\n",
    "            for j in range(restarts):\n",
    "                # randomly draw from unit sphere (step 2)\n",
    "                # u = np.random.randn(n_eigpos)\n",
    "                u = np.random.multivariate_normal(np.zeros(n_eigpos), np.eye(n_eigpos))\n",
    "                u /= np.linalg.norm(u)\n",
    "\n",
    "                # power iteration for N iterations\n",
    "                for i in range(N):\n",
    "                    u = T_map(M3_tilde, u)\n",
    "                    u /= np.linalg.norm(u)\n",
    "\n",
    "                # check for best eigenvalue\n",
    "                if j == 0 or (j > 0 and multimap(M3_tilde, [u, u, u]) > tau_star):\n",
    "                    tau_star = multimap(M3_tilde, [u, u, u])\n",
    "                    u_star = u\n",
    "\n",
    "            # N more power iterations for best eigenvector found\n",
    "            u = u_star\n",
    "            for i in range(N):\n",
    "                u = T_map(M3_tilde, u)\n",
    "                u /= np.linalg.norm(u)\n",
    "\n",
    "            # recovered modified (post-reduction) eigenvalue\n",
    "            lamb = (T_map(M3_tilde, u) / u)[0]\n",
    "\n",
    "            # recover original eigenvector and eigenvalue pair\n",
    "            mu_rec[:, b] = lamb * B @ u\n",
    "            lam_rec[b] = 1 / lamb**2\n",
    "\n",
    "            # deflation: remove component, repeat\n",
    "            M2 -= lam_rec[b] * np.outer(mu_rec[:, b], mu_rec[:, b])\n",
    "            M3 -= three_tensor_prod(\n",
    "                np.array(lam_rec[b]), mu_rec[:, b], mu_rec[:, b], mu_rec[:, b]\n",
    "            )\n",
    "\n",
    "    return mu_rec, lam_rec\n",
    "\n",
    "def lowrank(x, k):\n",
    "    u, s, vh = np.linalg.svd(x)\n",
    "    s_abs = np.abs(s)\n",
    "    inds = np.argsort(s_abs)[::-1][:k]\n",
    "    rec = np.zeros_like(x)\n",
    "    for i in inds:\n",
    "        rec += s[i] * np.outer(u.T[i], vh[i])\n",
    "    return rec\n",
    "\n",
    "class LabelModel():\n",
    "    def __init__(self, cardinality: int = 2, **kwargs: Any) -> None:\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def mu_recovery(self, triplet_idx_a, triplet_idx_b, triplet_idx_c):\n",
    "        \"\"\" Recover mu for a single labeling function (index triplet_index_a)\n",
    "            Follows the multi-view models approach (Section 3.3)\n",
    "            Constructs symmetric matrices / tensors from observed quantities\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            triplet_idx_a, triplet_idx_b, triplet_idx_c\n",
    "                Indices for the three labeling functions\n",
    "\n",
    "        \"\"\"\n",
    "        # setups for base matries and tensors     \n",
    "        if self.unipolar:\n",
    "            r = 2\n",
    "        else:\n",
    "            r = self.cardinality + 1 # for convenience\n",
    "        M2, M3 = np.zeros([r, r]), np.zeros([r, r, r])\n",
    "        x_tilde_1, x_tilde_2 = np.zeros((self.n, r)), np.zeros((self.n, r)) \n",
    "\n",
    "        # construct the main quantities, empirical two-tensors, pg. 2785\n",
    "        Ex3x2, Ex1x2, Ex3x1, Ex2x1 = np.zeros([r, r]), np.zeros([r, r]), np.zeros([r, r]), np.zeros([r, r])\n",
    "        if self.unipolar:\n",
    "            L = (self.L_train > -1).astype(int) - 1\n",
    "        else:\n",
    "            L = self.L_train\n",
    "        for i in range(r):\n",
    "            for j in range(r):\n",
    "                for k in range(self.n):\n",
    "                    Ex1x2[i, j] += (L[k,triplet_idx_a] == i-1 and L[k,triplet_idx_b] == j-1)\n",
    "                    Ex3x2[i, j] += (L[k,triplet_idx_c] == i-1 and L[k,triplet_idx_b] == j-1)\n",
    "                    Ex3x1[i, j] += (L[k,triplet_idx_c] == i-1 and L[k,triplet_idx_a] == j-1)\n",
    "                    Ex2x1[i, j] += (L[k,triplet_idx_b] == i-1 and L[k,triplet_idx_a] == j-1)\n",
    "\n",
    "        Ex3x2 /= self.n\n",
    "        Ex1x2 /= self.n\n",
    "        Ex3x1 /= self.n \n",
    "        Ex2x1 /= self.n\n",
    "\n",
    "        Ex3x2 = lowrank(Ex3x2, k=self.cardinality)\n",
    "        Ex1x2 = lowrank(Ex1x2, k=self.cardinality)\n",
    "        Ex3x1 = lowrank(Ex3x1, k=self.cardinality)\n",
    "        Ex2x1 = lowrank(Ex2x1, k=self.cardinality)\n",
    "\n",
    "        for k in range(self.n):\n",
    "            x1, x2, x3 = np.zeros(r), np.zeros(r), np.zeros(r)\n",
    "            x1[int(L[k,triplet_idx_a])+1] = 1\n",
    "            x2[int(L[k,triplet_idx_b])+1] = 1\n",
    "            x3[int(L[k,triplet_idx_c])+1] = 1\n",
    "\n",
    "            x_tilde_1[k] = Ex3x2 @ np.linalg.pinv(Ex1x2) @ x1\n",
    "            x_tilde_2[k] = Ex3x1 @ np.linalg.pinv(Ex2x1) @ x2              \n",
    "\n",
    "            # symmetrized versions, Theorem 3.6 pg. 2785\n",
    "            M2 += np.outer(x_tilde_1[k], x_tilde_2[k])\n",
    "            M3 += three_tensor_prod(np.array(1.0), x_tilde_1[k], x_tilde_2[k], x3)\n",
    "\n",
    "        M2 /= self.n\n",
    "        M3 /= self.n\n",
    "\n",
    "        # comps: we should recover at most the number of cardinality terms\n",
    "        mu_rec, lam_rec = tensor_decomp(M2, M3, self.cardinality)\n",
    "        print(f\"got mu_rec, lam_rec = {mu_rec} {lam_rec}\")\n",
    "        return mu_rec\n",
    "        \n",
    "    def fit(\n",
    "        self,\n",
    "        L_train: np.ndarray,\n",
    "    ) -> None:\n",
    "        self.n, self.m = L_train.shape\n",
    "        if self.m < 3:\n",
    "            raise ValueError(\"L_train should have at least 3 labeling functions\")\n",
    "\n",
    "        self.mu_numpy = np.zeros((self.m*self.cardinality, self.cardinality))\n",
    "        self.L_train = L_train\n",
    "        n_triplets = 1\n",
    "\n",
    "        # unipolarity affects algorithm; changes the rank of the tensor decomp\n",
    "        # assume all LFs are either unipolar or all multipolar\n",
    "        polarity = 0\n",
    "        for a in range(self.cardinality):\n",
    "            if np.sum(self.L_train[:, 0] == a) > 0:\n",
    "                polarity += 1\n",
    "        \n",
    "        self.unipolar = True if polarity < 2 else False\n",
    "        \n",
    "        # partition the LFs based on their unipolar votes\n",
    "        if self.unipolar:\n",
    "            self.unipolar_groups, self.unipolar_votes = {}, {}\n",
    "            for a in range(self.cardinality):\n",
    "                self.unipolar_groups[a] = []\n",
    "                for i in range(self.m):\n",
    "                    if np.sum(self.L_train[:, i] == a) > 0:\n",
    "                        self.unipolar_groups[a] += [i]\n",
    "                        self.unipolar_votes[i] = a\n",
    "\n",
    "        # keep track of overlaps in order to obtain the least noisy triplet\n",
    "        overlaps = np.zeros((self.m, self.m))\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.m):\n",
    "                overlaps[i, j] =  np.sum((self.L_train[:, i] > -1) & (self.L_train[:, j] > -1) & (self.L_train[:, i] == self.L_train[:, j]))\n",
    "\n",
    "        for i in range(self.m):\n",
    "            # select triplets\n",
    "            if self.unipolar:\n",
    "                idxes = self.unipolar_groups[self.unipolar_votes[i]].copy()\n",
    "            else:\n",
    "                idxes = list(range(self.m))\n",
    "            idxes.remove(i)\n",
    "            idxes = np.random.permutation(idxes)\n",
    "            b, c = idxes[0], idxes[1]\n",
    "            \n",
    "            # get best overlaps\n",
    "            for k, l in itertools.combinations(idxes, 2):\n",
    "                if overlaps[i, k] + overlaps[k, l] + overlaps[i, l] > overlaps[i,b] + overlaps[i, c] + overlaps[b, c]:\n",
    "                    b, c = k, l\n",
    "            mu_rec = self.mu_recovery(b, c, i)\n",
    "\n",
    "            # set the recovered mu component\n",
    "            if self.unipolar:\n",
    "                self.mu_numpy[i*self.cardinality + self.unipolar_votes[i], :] += mu_rec[1, :]\n",
    "            else:\n",
    "                self.mu_numpy[i*self.cardinality:(i+1)*self.cardinality, :] += mu_rec[1:, :]\n",
    "             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test recovery for synthetic mus\n",
    "\n",
    "Generate some simple data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cardinality 2 case\n",
    "def generate_synthetic(n, p, mu1, mu2, mu3):\n",
    "    y, L = np.zeros(n), np.zeros((n, 3))\n",
    "\n",
    "    for i in range(n):\n",
    "        y[i] = np.random.choice(2, 1, p=p)\n",
    "        L[i, 0] = np.random.choice(3, 1, p=mu1[:,int(y[i])]) - 1\n",
    "        L[i, 1] = np.random.choice(3, 1, p=mu2[:,int(y[i])]) - 1\n",
    "        L[i, 2] = np.random.choice(3, 1, p=mu3[:,int(y[i])]) - 1\n",
    "\n",
    "    return L, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu_true[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_true = np.zeros((9,2))\n",
    "\n",
    "# mu's for three LFs\n",
    "# multipolar case\n",
    "mu_true[0:3,:] = np.array([[0.6,0.7], [0.3, 0.1], [0.1, 0.2]])\n",
    "mu_true[3:6,:] = np.array([[0.55,0.6], [0.4, 0.1], [0.05, 0.3]])\n",
    "mu_true[6:9,:] = np.array([[0.5,0.7], [0.4, 0.05], [0.1, 0.25]])\n",
    "\n",
    "n = 100 \n",
    "w = np.array([0.3,0.7])\n",
    "\n",
    "L, Y = generate_synthetic(n, w,  mu_true[0:3,:], mu_true[3:6,:] , mu_true[6:9,:])\n",
    "Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with 10000 samples\n",
      "got mu_rec, lam_rec = [[0.66998758 0.        ]\n",
      " [0.15782961 0.        ]\n",
      " [0.17192876 0.        ]] [1.00044762 0.        ]\n",
      "got mu_rec, lam_rec = [[0.58007223 0.        ]\n",
      " [0.18071107 0.        ]\n",
      " [0.23731416 0.        ]] [0.99933828 0.        ]\n",
      "got mu_rec, lam_rec = [[0.66474852 0.        ]\n",
      " [0.13469038 0.        ]\n",
      " [0.21421256 0.        ]] [0.95902947 0.        ]\n",
      "for 10000 samples, recovery error 0.8767689350675498\n"
     ]
    }
   ],
   "source": [
    "# generate some samples and evaluate\n",
    "mu_true = np.zeros((9,2))\n",
    "\n",
    "# mu's for three LFs\n",
    "# multipolar case\n",
    "mu_true[0:3,:] = np.array([[0.6,0.7], [0.3, 0.1], [0.1, 0.2]])\n",
    "mu_true[3:6,:] = np.array([[0.55,0.6], [0.4, 0.1], [0.05, 0.3]])\n",
    "mu_true[6:9,:] = np.array([[0.5,0.7], [0.4, 0.05], [0.1, 0.25]])\n",
    "'''\n",
    "# unipolar case\n",
    "mu_true[0:3,:] = np.array([[0.6,0.9], [0.4, 0.1], [0.0, 0.0]])\n",
    "mu_true[3:6,:] = np.array([[0.55,0.8], [0.45, 0.2], [0.0, 0.0]])\n",
    "mu_true[6:9,:] = np.array([[0.7,0.95], [0.3, 0.05], [0.0, 0.0]])\n",
    "'''\n",
    "\n",
    "# class balance\n",
    "w = np.array([0.3,0.7])\n",
    "\n",
    "for ex in range(4,7):\n",
    "    n = 10**ex\n",
    "    print(f\"working with {n} samples\")\n",
    "    a = time.time()\n",
    "    L, Y = generate_synthetic(n, w,  mu_true[0:3,:], mu_true[3:6,:] , mu_true[6:9,:])\n",
    "    #L, Y = generate_synthetic(n, w,  mu1, mu2, mu3)\n",
    "    \n",
    "    label_model = LabelModel(cardinality=2)\n",
    "    label_model.fit(L)\n",
    "\n",
    "    # parameter recovery error on the mu's\n",
    "    tot_param_err = 0\n",
    "    for i in range(3):\n",
    "        tot_param_err += np.sum(np.abs(mu_true[3*i+1,:]-label_model.mu_numpy[2*i,:]))\n",
    "    #print(label_model.mu_numpy)\n",
    "    print(f\"for {n} samples, recovery error {tot_param_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
